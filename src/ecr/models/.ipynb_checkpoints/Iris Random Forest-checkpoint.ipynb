{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path ../iris/test_dir/input/data\n",
      "output_path ../iris/test_dir/output\n",
      "model_path ../iris/test_dir/model\n"
     ]
    }
   ],
   "source": [
    "prefix = '../iris/test_dir/'\n",
    "\n",
    "input_path = prefix + 'input/data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "\n",
    "print(\"input_path\", input_path)\n",
    "print(\"output_path\", output_path)\n",
    "print(\"model_path\", model_path)\n",
    "\n",
    "channel_name='training'\n",
    "training_path = os.path.join(input_path, channel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training.\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "    print('Starting the training.')\n",
    "    try:\n",
    "\n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError(('There are no files in {}.\\n' +\n",
    "                              'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        raw_data = [ pd.read_csv(file, header=None) for file in input_files ]\n",
    "        train_data = pd.concat(raw_data)\n",
    "\n",
    "        # labels are in the first column\n",
    "        train_y = train_data.iloc[:,0]\n",
    "        train_X = train_data.iloc[:,1:]\n",
    "\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        grid_params = [{\n",
    "            \"max_features\" : [\"auto\",\"log2\",0.20, 0.30],\n",
    "            \"n_estimators\" : [10,50,100],\n",
    "            \"min_samples_leaf\" : [25, 50, 100]\n",
    "        }]\n",
    "\n",
    "        scoring = {\n",
    "            'acc':'accuracy',\n",
    "            'precision':'precision',\n",
    "            'recall':'recall',\n",
    "            'auc':'roc_auc',\n",
    "            'mse':'neg_mean_squared_error',\n",
    "            'r2':'r2'\n",
    "        }\n",
    "\n",
    "        grid_clf = GridSearchCV(\n",
    "            estimator = clf, \n",
    "            param_grid=grid_params, \n",
    "            cv=5, \n",
    "#             scoring=scoring,\n",
    "            refit='auc',\n",
    "            n_jobs=-1,verbose=1,return_train_score=False)\n",
    "\n",
    "        grid_clf.fit(train_X, train_y)\n",
    "\n",
    "        # save the model\n",
    "        with open(os.path.join(model_path, 'iris-randomforest.pkl'), 'wb') as out:\n",
    "            pickle.dump(grid_clf, out, protocol=0)\n",
    "        print('Training complete.')\n",
    "\n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\n' + trc, file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

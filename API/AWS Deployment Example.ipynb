{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "%run AWS_functions.py\n",
    "\n",
    "session = boto3.session.Session()\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "ec2_resource = boto3.resource(\"ec2\")\n",
    "ec2_client = boto3.client('ec2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Following Workflow\n",
    "\n",
    "### [File Storage](#File_Storage)\n",
    "* [Create](#File_Storage_Create) an **S3 Bucket**\n",
    "* [Load](#File_Storage_Load) csv file and script to execute\n",
    "* [Delete](#File_Storage_Delete) object and content\n",
    "* [List](#File_Storage_List) objects\n",
    "\n",
    "### [Execute Code](#Execute_Code)\n",
    "#### [EC2](#Execute_Code_EC2) Miniconda Image\n",
    "* [Create](#Execute_Code_EC2_Create) the EC2 Instance\n",
    "* [Mount](#Execute_Code_EC2_Mount) S3 Storage\n",
    "* [Execute](#Execute_Code_EC2_Script) Script\n",
    "* [Stop](#Execute_Code_EC2_Stop) \\ Terminate server\n",
    "\n",
    "#### [SageMaker](#Execute_Code_SM) Instance\n",
    "* [Create](#Execute_Code_SM_Create) SageView\n",
    "* Mount S3 Storage\n",
    "* Execute Script\n",
    "\n",
    "### Requirements\n",
    "pycloud environment\n",
    "```\n",
    "conda env create -f pycloud.env.ymp --force\n",
    "```\n",
    "\n",
    "From Command line execute `aws configure` in order to setup your AWS Access Key and AWS Secret Key\n",
    "\n",
    "Local Test Code is located under `example_src`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## File Storage<a id=\"File_Storage\"></a>\n",
    "Code to create an S3 Storage\n",
    "https://realpython.com/python-boto3-aws-s3/#creating-a-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Object<a id=\"File_Storage_Create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122 us-east-1\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "bucket_name, first_response = aws_create_bucket(\n",
    "    bucket_name='iris-train', \n",
    "    s3_connection=s3_resource.meta.client,\n",
    "    current_region=session.region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files into S3 Object<a id=\"File_Storage_Load\"></a>\n",
    "There is no native folder sync within Python SDK, so using aws command to solve for this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3.6 KiB/5.7 KiB (23.0 KiB/s) with 3 file(s) remaining\n",
      "upload: ../example_src/iris/data/iris.csv to s3://iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122/data/iris.csv\n",
      "Completed 3.6 KiB/5.7 KiB (23.0 KiB/s) with 2 file(s) remaining\n",
      "Completed 3.6 KiB/5.7 KiB (13.7 KiB/s) with 2 file(s) remaining\n",
      "upload: ../example_src/iris/requirements.txt to s3://iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122/requirements.txt\n",
      "Completed 3.6 KiB/5.7 KiB (13.7 KiB/s) with 1 file(s) remaining\n",
      "Completed 5.7 KiB/5.7 KiB (19.6 KiB/s) with 1 file(s) remaining\n",
      "upload: ../example_src/iris/iris_train.py to s3://iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122/iris_train.py\n",
      "\n",
      "Uploaded was a True\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "success = aws_upload_files_to_bucket(\n",
    "    path_to_src=\"../example_src/iris\", \n",
    "    bucket_name=bucket_name)\n",
    "\n",
    "print(\"Uploaded was a\", success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to EC2](#Execute_Code_EC2)\n",
    "[Go to SageMaker](#Execute_Code_SM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete S3 Object and Content<a id=\"File_Storage_Delete\"></a>\n",
    "Remove all resources and delete bucket!<br>\n",
    "**This does not back-up anything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': '.DS_Store', 'VersionId': 'null'}, {'Key': '.ipynb_checkpoints/Untitled-checkpoint.ipynb', 'VersionId': 'null'}, {'Key': 'Untitled.ipynb', 'VersionId': 'null'}, {'Key': 'data/.DS_Store', 'VersionId': 'null'}, {'Key': 'data/chicagoCrimes10k.csv', 'VersionId': 'null'}, {'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/HasDetections_GridSearch_RF_final.pkl', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'notebooks/.ipynb_checkpoints/ChicagoCrime-RF-checkpoint.ipynb', 'VersionId': 'null'}, {'Key': 'notebooks/ChicagoCrime-RF.ipynb', 'VersionId': 'null'}, {'Key': 'output/failure', 'VersionId': 'null'}, {'Key': 'requirements.txt', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'sm_train.py', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "aws_delete_bucket(bucket_name, s3_resource)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List S3 Buckets<a id=File_Storage_List></a>\n",
    "Quickly list and clean up all buckets created by with iris-trian in name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "for bucket in s3_resource.buckets.all():\n",
    "  if \"iris-train\" in bucket.name:\n",
    "    print(bucket.name)\n",
    "#     aws_delete_bucket(bucket.name, s3_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Execute Code<a id=Execute_Code></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Instance<a id=Execute_Code_EC2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EC2 Instance<a id=Execute_Code_EC2_Create></a>\n",
    "https://blog.ipswitch.com/how-to-create-an-ec2-instance-with-python\n",
    "\n",
    "You need to bring your own:\n",
    "* Security Group\n",
    "* pem key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building the following EC2\n",
    "* MiniConda - ami-062c42cbecc1d5ec0\n",
    "* t2.medium\n",
    "\n",
    "I built my own security group and granted ssh access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a bash script to create the S3 Mount, go [here](#Execute_Code_EC2_Mount) to see details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount S3 onto EC2 Instance<a id=Execute_Code_EC2_Mount></a>\n",
    "https://cloudkul.com/blog/mounting-s3-bucket-linux-ec2-instance/\n",
    "\n",
    "Using existing EC2 in AWS\n",
    "Need to leverage API to create EC2 and mount determining setup\n",
    "\n",
    "**Required setup on EC2**\n",
    "```\n",
    "sudo yum update\n",
    "sudo yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel\n",
    "git clone https://github.com/s3fs-fuse/s3fs-fuse.git\n",
    "cd s3fs-fuse\n",
    "./autogen.sh\n",
    "./configure --prefix=/usr --with-openssl\n",
    "make\n",
    "sudo make install\n",
    "```\n",
    "\n",
    "You must create an IAM role for S3 Mounting, for sake of simplicity, i'm using my Admin IAM Access\n",
    "```\n",
    "sudo touch /etc/passwd-s3fs\n",
    "sudo vim /etc/passwd-s3fs\n",
    "```\n",
    "Provide `Your_accesskey:Your_secretkey` inside the file\n",
    "```\n",
    "sudo chmod 640 /etc/passwd-s3fs\n",
    "```\n",
    "\n",
    "Let's mount it!, replace iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 with your bucket name\n",
    "uid=500 is ec2-user account\n",
    "```\n",
    "sudo mkdir /mys3bucket\n",
    "sudo chown ec2-user:ec2-user /mys3bucket\n",
    "s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "\n",
    "Validate\n",
    "```\n",
    "df -Th\n",
    "```\n",
    "\n",
    "Mount at reboot\n",
    "```\n",
    "vi /etc/rc.local\n",
    "/usr/bin/s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "**or** add it to the User Data at execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance id:  i-0c4e0a21c3f6164a9\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "from IPython.display import display\n",
    "import socket\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# create a new EC2 instance\n",
    "user_data = aws_user_data_script(bucket_name)\n",
    "\n",
    "instance = aws_create_ec2_instance(\n",
    "    ec2_name=\"iris-train\", \n",
    "    security_group=['sg-0d24aec64507df8b5'], \n",
    "    user_data=user_data, \n",
    "    ec2_resource=ec2_resource,\n",
    "    image_id = \"ami-062c42cbecc1d5ec0\", \n",
    "    instance_type=\"t2.medium\")\n",
    "\n",
    "print(\"instance id: \",instance.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait till instance state changes to running\n",
      "Instance State Up, waiting for boot-up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'instance is still loading retrying . . . '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance is UP & accessible on port 22, the IP address is:   3.80.171.61\n"
     ]
    }
   ],
   "source": [
    "#Provide status when instance is finally up!\n",
    "retries = 10\n",
    "retry_delay = 10\n",
    "retry_count = 0\n",
    "\n",
    "print(\"Wait till instance state changes to running\")\n",
    "instance.wait_until_running()\n",
    "instance = ec2_resource.Instance(id=instance.id)\n",
    "print(\"Instance State Up, waiting for boot-up\")\n",
    "\n",
    "waiting_status = \"instance is still loading retrying . . . \"\n",
    "dh = display(waiting_status,display_id=True)\n",
    "\n",
    "while retry_count <= retries:\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex((instance.public_ip_address,22))\n",
    "    if result == 0:\n",
    "        print(\"Instance is UP & accessible on port 22, the IP address is:  \",instance.public_ip_address)\n",
    "        break\n",
    "    else:\n",
    "        if len(waiting_status) < 50:\n",
    "            waiting_status += \". \"\n",
    "        else:\n",
    "            waiting_status = waiting_status[0:41]\n",
    "\n",
    "        dh.update(waiting_status)\n",
    "        time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands via SSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can tell miniconda app happens after UserData is complete, thus no installing conda environment\n",
    "\n",
    "We will execute the following command through ssh client via root access\n",
    "```\n",
    "sudo su\n",
    "while read requirement; do conda install --yes $requirement; done < /mys3bucket/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                        main  \n",
      "asn1crypto                0.24.0                   py37_0  \n",
      "blas                      1.0                         mkl  \n",
      "ca-certificates           2019.10.16                    0  \n",
      "certifi                   2019.9.11                py37_0  \n",
      "cffi                      1.11.5           py37he75722e_1  \n",
      "chardet                   3.0.4                    py37_1  \n",
      "conda                     4.5.12                   py37_0  \n",
      "conda-env                 2.6.0                         1  \n",
      "cryptography              2.4.2            py37h1ba5d50_0  \n",
      "idna                      2.8                      py37_0  \n",
      "intel-openmp              2019.4                      243  \n",
      "joblib                    0.14.0                     py_0  \n",
      "libedit                   3.1.20181209         hc058e9b_0  \n",
      "libffi                    3.2.1                hd88cf55_4  \n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \n",
      "libstdcxx-ng              8.2.0                hdf63c60_1  \n",
      "mkl                       2019.4                      243  \n",
      "mkl-service               2.3.0            py37he904b0f_0  \n",
      "mkl_fft                   1.0.15           py37ha843d7b_0  \n",
      "mkl_random                1.1.0            py37hd6b4f25_0  \n",
      "ncurses                   6.1                  he6710b0_1  \n",
      "numpy                     1.17.3           py37hd14ec0e_0  \n",
      "numpy-base                1.17.3           py37hde5b4d6_0  \n",
      "openssl                   1.0.2t               h7b6447c_1  \n",
      "pandas                    0.25.2           py37he6710b0_0  \n",
      "pip                       19.3.1                   py37_0  \n",
      "pycosat                   0.6.3            py37h14c3975_0  \n",
      "pycparser                 2.19                     py37_0  \n",
      "pyopenssl                 18.0.0                   py37_0  \n",
      "pysocks                   1.6.8                    py37_0  \n",
      "python                    3.7.0                h6e4f718_3  \n",
      "python-dateutil           2.8.1                      py_0  \n",
      "pytz                      2019.3                     py_0  \n",
      "readline                  7.0                  h7b6447c_5  \n",
      "requests                  2.21.0                   py37_0  \n",
      "ruamel_yaml               0.15.46          py37h14c3975_0  \n",
      "scikit-learn              0.21.3           py37hd81dba3_0  \n",
      "scipy                     1.3.1            py37h7c811a0_0  \n",
      "setuptools                41.6.0                   py37_0  \n",
      "six                       1.12.0                   py37_0  \n",
      "sqlite                    3.30.1               h7b6447c_0  \n",
      "tk                        8.6.8                hbc83047_0  \n",
      "urllib3                   1.24.1                   py37_0  \n",
      "wheel                     0.33.6                   py37_0  \n",
      "xz                        5.2.4                h14c3975_4  \n",
      "yaml                      0.1.7                had09818_2  \n",
      "zlib                      1.2.11               h7b6447c_3  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "commands = [\n",
    "    \"mkdir /mys3bucket/output\",\n",
    "    \"mkdir /mys3bucket/model\",\n",
    "    \"echo 'for requirement in `cat /mys3bucket/requirements.txt` ; do  conda install --yes  ${requirement}  ;  done' > /tmp/setup.sh\",\n",
    "    \"chmod +x /tmp/setup.sh\",\n",
    "    \"sudo  -i /tmp/setup.sh\",\n",
    "    \"conda list\"\n",
    "]\n",
    "\n",
    "ssh_result = exec_ssh_cmd(instance.public_ip_address,commands)\n",
    "\n",
    "#Print the last line conda list\n",
    "[print(l) for l in ssh_result[5][\"response\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Python Script<a id=Execute_Code_EC2_Script></a>\n",
    "\n",
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data\n",
      "trian model\n",
      "save model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "ssh_result = exec_ssh_cmd(\n",
    "    public_dns_name = instance.public_ip_address,\n",
    "    commands = [\"cd /mys3bucket/; python iris_train.py\"])\n",
    "\n",
    "[ print(val) for val in ssh_result[0][\"response\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for S3 to refresh then download and kill instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 564 Bytes/9.1 KiB (2.5 KiB/s) with 2 file(s) remaining\n",
      "download: s3://iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122/model/iris-labels.pkl to ../example_src/iris/model/iris-labels.pkl\n",
      "Completed 564 Bytes/9.1 KiB (2.5 KiB/s) with 1 file(s) remaining\n",
      "Completed 9.1 KiB/9.1 KiB (40.8 KiB/s) with 1 file(s) remaining \n",
      "download: s3://iris-train-12746b8f-be9f-4ef8-8c06-38323c33c122/model/iris-rf.pkl to ../example_src/iris/model/iris-rf.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "resources, bucket = aws_list_objects(\n",
    "    bucket_name=bucket_name,\n",
    "    s3_resource=s3_resource)\n",
    "\n",
    "models = [ res[\"file_name\"] for res in resources if \"model/iris\" in res[\"file_name\"]]\n",
    "models\n",
    "\n",
    "if len(models) > 0:\n",
    "    aws_download_objects(\n",
    "        path_to_src=\"../example_src/iris\",\n",
    "        bucket_name=bucket_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop \\ Terminate EC2 Instance<a id=Execute_Code_EC2_Stop></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StoppingInstances': [{'CurrentState': {'Code': 64, 'Name': 'stopping'}, 'InstanceId': 'i-0c4e0a21c3f6164a9', 'PreviousState': {'Code': 16, 'Name': 'running'}}], 'ResponseMetadata': {'RequestId': '747e5d07-623a-42fe-95f9-07bea87604fa', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8', 'content-length': '579', 'date': 'Fri, 15 Nov 2019 20:50:26 GMT', 'server': 'AmazonEC2'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "%run AWS_functions.py\n",
    "\n",
    "response = aws_stop_ec2(\n",
    "    instance_id = instance.id, \n",
    "    ec2_client = ec2_client)\n",
    "\n",
    "print( response )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model\n",
    "\n",
    "https://medium.com/@patrickmichelberger/how-to-deploy-a-serverless-machine-learning-microservice-with-aws-lambda-aws-api-gateway-and-d5b8cbead846\n",
    "\n",
    "We used a mircoserver flask and zappa to automate lambda, s3, and api gateway\n",
    "\n",
    "*Assumptions*\n",
    "* Flask app created in the project folder under api folder and works locally\n",
    "* Pickle \\ joblib file uploaded to s3\n",
    "* virtualenv installed `pip install virtualenv`\n",
    "\n",
    "1) Setup a lambda virtualenv from your project folder\n",
    "```\n",
    "cd example_src\\iris\n",
    "virtualenv lambda\n",
    "source lambda/bin/activate\n",
    "pip install flask zappa sklearn numpy scipy\n",
    "```\n",
    "2) Test your flask locally by running `python api/app.py`\n",
    "3) Initialize zappa by `zappa init`\n",
    "    * Environment: dev\n",
    "    * S3 Bucket: use default\n",
    "    * App Function: use default `api.app.app`\n",
    "    * Globally: n\n",
    "*Should look like this*\n",
    "```\n",
    "{\n",
    "    \"dev\": {\n",
    "        \"app_function\": \"api.app.app\",\n",
    "        \"aws_region\": \"us-east-1\",\n",
    "        \"profile_name\": \"default\",\n",
    "        \"project_name\": \"iris\",\n",
    "        \"runtime\": \"python3.7\",\n",
    "        \"s3_bucket\": \"zappa-telpd5in0\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "4) Deploy zappa \n",
    "```zappa deploy dev```<br>\n",
    "5) Test Model<br>\n",
    "```\n",
    "curl -d '{\"data\":[[4, 2.1,1,0.4], [6.2, 1,3,2]]}' -X POST https://sgj5uofirg.execute-api.us-east-1.amazonaws.com/dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Sagemaker<a id=Execute_Code_SM></a>\n",
    "Sagemaker requires setting up the S3 Folder Structure alittle differently\n",
    "```\n",
    "example_src/\n",
    "+----data/\n",
    "    +--iris.csv\n",
    "+----output/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup S3<a id=Execute_Code_SM_S3></a>\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris/Scikit-learn%20Estimator%20Example%20With%20Batch%20Transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# from sagemaker import get_execution_role\n",
    "# role = get_execution_role()\n",
    "# role\n",
    "role = \"arn:aws:iam::741519135447:role/service-role/AmazonSageMaker-ExecutionRole-20191018T183794\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-741519135447/iris-train/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset, then join labels and features\n",
    "# iris = datasets.load_iris()\n",
    "# joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# # Create directory and write csv\n",
    "# os.makedirs('./data', exist_ok=True)\n",
    "# np.savetxt('./data/iris.csv', joined_iris, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')\n",
    "\n",
    "# WORK_DIRECTORY = 'data'\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    '../example_src/iris/data', \n",
    "    key_prefix=\"{}/{}\".format(\"iris-train\", 'data') )\n",
    "\n",
    "print(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = '../example_src/iris/train.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-16 17:40:58 Starting - Starting the training job...\n",
      "2019-11-16 17:40:59 Starting - Launching requested ML instances...\n",
      "2019-11-16 17:42:00 Starting - Preparing the instances for training......\n",
      "2019-11-16 17:42:57 Downloading - Downloading input data...\n",
      "2019-11-16 17:43:25 Training - Downloading the training image..\u001b[31m2019-11-16 17:43:39,354 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,357 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,367 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,629 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,629 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,629 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:39,630 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=6305 sha256=65d943cfa68d6e7747a1f5a05b9040124b80ad14d75bed2927ca993d886ca5a4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0pe4472b/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:41,129 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:41,140 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-11-16-17-40-57-075\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-16-17-40-57-075/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-16-17-40-57-075/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2019-11-16-17-40-57-075\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-16-17-40-57-075/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/miniconda3/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[31mload data\u001b[0m\n",
      "\u001b[31mtrian model\u001b[0m\n",
      "\u001b[31mAccuracy: 0.8666666666666667\u001b[0m\n",
      "\u001b[31msave model\u001b[0m\n",
      "\u001b[31m2019-11-16 17:43:42,505 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-11-16 17:43:49 Uploading - Uploading generated training model\n",
      "2019-11-16 17:43:49 Completed - Training job completed\n",
      "Training seconds: 52\n",
      "Billable seconds: 52\n"
     ]
    }
   ],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sagemaker-scikit-learn-2019-11-16-17-40-57-075: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-fbafc7f42df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ml.m4.xlarge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             )\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m    980\u001b[0m         )\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   1177\u001b[0m                 ),\n\u001b[1;32m   1178\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m             )\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sagemaker-scikit-learn-2019-11-16-17-40-57-075: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"../example_src/iris/data/iris.csv\")\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "test_X = test_data.iloc[:,1:]\n",
    "test_y = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-74840b08a93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(predictor.predict(test_X.values))\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for requirement in `cat /mys3bucket/requirements.txt` ; do  pip install --yes  ${requirement}  ;  done\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

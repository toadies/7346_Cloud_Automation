{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "Following Workflow\n",
    "\n",
    "### [File Storage](#File_Storage)\n",
    "* [Create](#File_Storage_Create) an **S3 Bucket**\n",
    "* [Load](#File_Storage_Load) csv file and script to execute\n",
    "* [Delete](#File_Storage_Delete) object and content\n",
    "* [List](#File_Storage_List) objects\n",
    "\n",
    "### [Execute Code](#Execute_Code)\n",
    "#### [EC2](#Execute_Code_EC2) Miniconda Image\n",
    "* [Create](#Execute_Code_EC2_Create) the EC2 Instance\n",
    "* [Mount](#Execute_Code_EC2_Mount) S3 Storage\n",
    "* [Execute](#Execute_Code_EC2_Script) Script\n",
    "* [Stop](#Execute_Code_EC2_Stop) \\ Terminate server\n",
    "\n",
    "#### SageView Instance\n",
    "* Create SageView\n",
    "* Mount S3 Storage\n",
    "* Execute Script\n",
    "\n",
    "### Requirements\n",
    "pycloud environment\n",
    "```\n",
    "conda env create -f pycloud.env.ymp --force\n",
    "```\n",
    "\n",
    "From Command line execute `aws configure` in order to setup your AWS Access Key and AWS Secret Key\n",
    "\n",
    "Local Test Code is located under `example_src`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## File Storage<a id=\"File_Storage\"></a>\n",
    "Code to create an S3 Storage\n",
    "https://realpython.com/python-boto3-aws-s3/#creating-a-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Object<a id=\"File_Storage_Create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_bucket_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])\n",
    "\n",
    "def create_bucket(bucket_prefix, s3_connection):\n",
    "    session = boto3.session.Session()\n",
    "    current_region = session.region_name\n",
    "    # Create Configurations\n",
    "    configs = {}\n",
    "    if current_region != \"us-east-1\":\n",
    "        config[\"LocationConstraint\"] = current_region\n",
    "\n",
    "    bucket_name = create_bucket_name(bucket_prefix)\n",
    "    \n",
    "    if current_region == \"us-east-1\":\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={\"LocationConstraint\":current_region})\n",
    "        \n",
    "    print(bucket_name, current_region)\n",
    "    return bucket_name, bucket_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-traina4f049e0-019d-442e-ba86-69591260780d us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name, first_response = create_bucket(\n",
    "    bucket_prefix='iris-train', \n",
    "    s3_connection=s3_resource.meta.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files into S3 Object<a id=\"File_Storage_Load\"></a>\n",
    "There is no native folder sync within Python SDK, so using aws command to solve for this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3.6 KiB/73.8 KiB (13.8 KiB/s) with 5 file(s) remaining\n",
      "upload: ../example_src/data/training/iris.csv to s3://iris-traina4f049e0-019d-442e-ba86-69591260780d/data/training/iris.csv\n",
      "Completed 3.6 KiB/73.8 KiB (13.8 KiB/s) with 4 file(s) remaining\n",
      "Completed 3.6 KiB/73.8 KiB (12.5 KiB/s) with 4 file(s) remaining\n",
      "upload: ../example_src/requirements.txt to s3://iris-traina4f049e0-019d-442e-ba86-69591260780d/requirements.txt\n",
      "Completed 3.6 KiB/73.8 KiB (12.5 KiB/s) with 3 file(s) remaining\n",
      "Completed 3.8 KiB/73.8 KiB (12.9 KiB/s) with 3 file(s) remaining\n",
      "upload: ../example_src/requirements.yml to s3://iris-traina4f049e0-019d-442e-ba86-69591260780d/requirements.yml\n",
      "Completed 3.8 KiB/73.8 KiB (12.9 KiB/s) with 2 file(s) remaining\n",
      "Completed 7.4 KiB/73.8 KiB (21.1 KiB/s) with 2 file(s) remaining\n",
      "upload: ../example_src/train.py to s3://iris-traina4f049e0-019d-442e-ba86-69591260780d/train.py\n",
      "Completed 7.4 KiB/73.8 KiB (21.1 KiB/s) with 1 file(s) remaining\n",
      "Completed 73.8 KiB/73.8 KiB (81.1 KiB/s) with 1 file(s) remaining\n",
      "upload: ../example_src/model/iris-randomforest.pkl to s3://iris-traina4f049e0-019d-442e-ba86-69591260780d/model/iris-randomforest.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "path_to_src = \"../example_src\"\n",
    "path_to_s3 = \"s3://\" + bucket_name\n",
    "\n",
    "# result = subprocess.run([\"aws\",\"s3\", \"sync\" ,path_to_src, path_to_s3,\"--acl\",\"private\"], stdout=subprocess.PIPE)\n",
    "\n",
    "result = os.popen(\"aws s3 sync \"+path_to_src+\" \"+path_to_s3+\" --acl private\").read()\n",
    "\n",
    "print(result)\n",
    "# [ print( l ) for l in result.stdout.decode('utf-8').split('\\n') ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete S3 Object and Content<a id=\"File_Storage_Delete\"></a>\n",
    "Remove all resources and delete bucket!<br>\n",
    "**This does not back-up anything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "def delete_all_objects(bucket_name):\n",
    "    res = []\n",
    "    bucket=s3_resource.Bucket(bucket_name)\n",
    "    for obj_version in bucket.object_versions.all():\n",
    "        res.append({'Key': obj_version.object_key,\n",
    "                    'VersionId': obj_version.id})\n",
    "    print(res)\n",
    "    bucket.delete_objects(Delete={'Objects': res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '47F879E285BFA452',\n",
       "  'HostId': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "   'x-amz-request-id': '47F879E285BFA452',\n",
       "   'date': 'Thu, 07 Nov 2019 00:51:55 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_all_objects(bucket_name)    \n",
    "\n",
    "s3_resource.Bucket(bucket_name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List S3 Buckets<a id=File_Storage_List></a>\n",
    "Quickly list and clean up all buckets created by with iris-trian in name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-train4c9a17e5-af2f-453f-9767-9cf97fa23769\n",
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.txt', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'text.txt', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n",
      "iris-traina35ddbe4-aab9-4186-aefc-7654bde70442\n",
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n",
      "iris-trainc0e3588c-d9bb-4699-821c-1883670ace42\n",
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n",
      "iris-traince510ef7-e35a-43ef-896e-ebb8980deafc\n",
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n",
      "iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a\n",
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.txt', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "for bucket in s3_resource.buckets.all():\n",
    "  if \"iris-train\" in bucket.name:\n",
    "    print(bucket.name)\n",
    "    delete_all_objects(bucket.name)  \n",
    "    s3_resource.Bucket(bucket.name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Execute Code<a id=Execute_Code></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Instance<a id=Execute_Code_EC2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EC2 Instance<a id=Execute_Code_EC2_Create></a>\n",
    "https://blog.ipswitch.com/how-to-create-an-ec2-instance-with-python\n",
    "\n",
    "You need to bring your own:\n",
    "* Security Group\n",
    "* pem key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building the following EC2\n",
    "* MiniConda - ami-062c42cbecc1d5ec0\n",
    "* t2.medium\n",
    "\n",
    "I built my own security group and granted ssh access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_ec2_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a bash script to create the S3 Mount, go [here](#Execute_Code_EC2_Mount) to see details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount S3 onto EC2 Instance<a id=Execute_Code_EC2_Mount></a>\n",
    "https://cloudkul.com/blog/mounting-s3-bucket-linux-ec2-instance/\n",
    "\n",
    "Using existing EC2 in AWS\n",
    "Need to leverage API to create EC2 and mount determining setup\n",
    "\n",
    "**Required setup on EC2**\n",
    "```\n",
    "sudo yum update\n",
    "sudo yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel\n",
    "git clone https://github.com/s3fs-fuse/s3fs-fuse.git\n",
    "cd s3fs-fuse\n",
    "./autogen.sh\n",
    "./configure --prefix=/usr --with-openssl\n",
    "make\n",
    "sudo make install\n",
    "```\n",
    "\n",
    "You must create an IAM role for S3 Mounting, for sake of simplicity, i'm using my Admin IAM Access\n",
    "```\n",
    "sudo touch /etc/passwd-s3fs\n",
    "sudo vim /etc/passwd-s3fs\n",
    "```\n",
    "Provide `Your_accesskey:Your_secretkey` inside the file\n",
    "```\n",
    "sudo chmod 640 /etc/passwd-s3fs\n",
    "```\n",
    "\n",
    "Let's mount it!, replace iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 with your bucket name\n",
    "uid=500 is ec2-user account\n",
    "```\n",
    "sudo mkdir /mys3bucket\n",
    "sudo chown ec2-user:ec2-user /mys3bucket\n",
    "s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "\n",
    "Validate\n",
    "```\n",
    "df -Th\n",
    "```\n",
    "\n",
    "Mount at reboot\n",
    "```\n",
    "vi /etc/rc.local\n",
    "/usr/bin/s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "**or** add it to the User Data at execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "user_data = [\n",
    "    \"#cloud-boothook\",\n",
    "    \"#!/bin/bash\",\n",
    "    \"yum update -q -y\",\n",
    "    \"yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -q -y\",\n",
    "    \"git clone https://github.com/s3fs-fuse/s3fs-fuse.git /tmp/s3fs-fuse\",\n",
    "    \"cd /tmp/s3fs-fuse\",\n",
    "    \"./autogen.sh\",\n",
    "    \"./configure --prefix=/usr --with-openssl\",\n",
    "    \"make\",\n",
    "    \"make install\",\n",
    "    'echo \"' + os.getenv(\"AWS_ACCESS_ID\") + ':' + os.getenv(\"AWS_SECRET_ACCESS_KEY\") + '\" > /tmp/passwd-s3fs',\n",
    "    \"mv -f /tmp/passwd-s3fs /etc\",\n",
    "    \"chmod 640 /etc/passwd-s3fs\",\n",
    "    \"mkdir -p /mys3bucket\",\n",
    "    \"chown ec2-user:ec2-user /mys3bucket\",\n",
    "    \"s3fs \" + bucket_name + \" -o use_cache=/tmp -o uid=500 -o mp_umask=002 -o multireq_max=5 -o allow_other /mys3bucket\",\n",
    "    # \"while read requirement; do conda install --yes $requirement; done < /mys3bucket/requirements.txt\"\n",
    "]\n",
    "user_data = \"\\n\".join(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance id:  i-027f499eb041d7c8e\n",
      "Wait till instance state changes to running\n",
      "Instance State Up, waiting for boot-up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'instance is still loading retrying . . . '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance is UP & accessible on port 22, the IP address is:   54.174.46.100\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import boto3\n",
    "import socket\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "# create a new EC2 instance\n",
    "ec2_name = create_ec2_name(\"iris-train\")\n",
    "security_group = ['sg-0d24aec64507df8b5'] # SSH allowed\n",
    "pem_key = \"ballenger-smu\"\n",
    "\n",
    "instances = ec2.create_instances(\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'instance',\n",
    "            'Tags': [\n",
    "                {\n",
    "                    'Key': 'Name',\n",
    "                    'Value': ec2_name\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    ImageId='ami-062c42cbecc1d5ec0',\n",
    "    MinCount=1,\n",
    "    MaxCount=1,\n",
    "    InstanceType='t2.micro',\n",
    "#     InstanceType='t2.medium',\n",
    "    KeyName=pem_key,\n",
    "    SecurityGroupIds=security_group, #Bring your own!\n",
    "    UserData=user_data\n",
    ")\n",
    "\n",
    "instance = instances[0]\n",
    "print(\"instance id: \",instance.id)\n",
    "\n",
    "#Provide status when instance is finally up!\n",
    "retries = 10\n",
    "retry_delay = 10\n",
    "retry_count = 0\n",
    "\n",
    "print(\"Wait till instance state changes to running\")\n",
    "instance.wait_until_running()\n",
    "instance = ec2.Instance(id=instance.id)\n",
    "print(\"Instance State Up, waiting for boot-up\")\n",
    "\n",
    "waiting_status = \"instance is still loading retrying . . . \"\n",
    "dh = display(waiting_status,display_id=True)\n",
    "\n",
    "while retry_count <= retries:\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex((instance.public_ip_address,22))\n",
    "    if result == 0:\n",
    "        print(\"Instance is UP & accessible on port 22, the IP address is:  \",instance.public_ip_address)\n",
    "        break\n",
    "    else:\n",
    "        if len(waiting_status) < 50:\n",
    "            waiting_status += \". \"\n",
    "        else:\n",
    "            waiting_status = waiting_status[0:41]\n",
    "\n",
    "        dh.update(waiting_status)\n",
    "        time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands via SSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can tell miniconda app happens after UserData is complete, thus no installing conda environment\n",
    "\n",
    "We will execute the following command through ssh client via root access\n",
    "```\n",
    "sudo su\n",
    "while read requirement; do conda install --yes $requirement; done < /mys3bucket/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Python Script<a id=Execute_Code_EC2_Script></a>\n",
    "\n",
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop \\ Terminate EC2 Instance<a id=Execute_Code_EC2_Stop></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('ec2')\n",
    "\n",
    "response = client.stop_instances(\n",
    "    InstanceIds=[\n",
    "        instances[0].id,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StoppingInstances': [{'CurrentState': {'Code': 64, 'Name': 'stopping'},\n",
       "   'InstanceId': 'i-027f499eb041d7c8e',\n",
       "   'PreviousState': {'Code': 64, 'Name': 'stopping'}}],\n",
       " 'ResponseMetadata': {'RequestId': '74ddc666-5a0f-4b8e-a16d-68b803786231',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '580',\n",
       "   'date': 'Sat, 09 Nov 2019 17:22:22 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

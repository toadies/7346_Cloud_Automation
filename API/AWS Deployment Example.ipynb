{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "Following Workflow\n",
    "\n",
    "### [File Storage](#File_Storage)\n",
    "* [Create](#File_Storage_Create) an **S3 Bucket**\n",
    "* [Load](#File_Storage_Load) csv file and script to execute\n",
    "* [Delete](#File_Storage_Delete) object and content\n",
    "* [List](#File_Storage_List) objects\n",
    "\n",
    "### [Execute Code](#Execute_Code)\n",
    "#### [EC2](#Execute_Code_EC2) Miniconda Image\n",
    "* [Create](#Execute_Code_EC2_Create) the EC2 Instance\n",
    "* [Mount](#Execute_Code_EC2_Mount) S3 Storage\n",
    "* [Execute](#Execute_Code_EC2_Script) Script\n",
    "* [Stop](#Execute_Code_EC2_Stop) \\ Terminate server\n",
    "\n",
    "#### [SageMaker](#Execute_Code_SM) Instance\n",
    "* [Create](#Execute_Code_SM_Create) SageView\n",
    "* Mount S3 Storage\n",
    "* Execute Script\n",
    "\n",
    "### Requirements\n",
    "pycloud environment\n",
    "```\n",
    "conda env create -f pycloud.env.ymp --force\n",
    "```\n",
    "\n",
    "From Command line execute `aws configure` in order to setup your AWS Access Key and AWS Secret Key\n",
    "\n",
    "Local Test Code is located under `example_src`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## File Storage<a id=\"File_Storage\"></a>\n",
    "Code to create an S3 Storage\n",
    "https://realpython.com/python-boto3-aws-s3/#creating-a-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Object<a id=\"File_Storage_Create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_bucket_name(bucket_name, include_uid = False):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    if include_uid:\n",
    "        return ''.join([bucket_name, str(uuid.uuid4())])\n",
    "    else:\n",
    "        return bucket_name\n",
    "\n",
    "def create_bucket(bucket_name, s3_connection):\n",
    "    session = boto3.session.Session()\n",
    "    current_region = session.region_name\n",
    "    # Create Configurations\n",
    "    configs = {}\n",
    "    if current_region != \"us-east-1\":\n",
    "        config[\"LocationConstraint\"] = current_region\n",
    "\n",
    "    bucket_name = create_bucket_name(bucket_name, True)\n",
    "    \n",
    "    if current_region == \"us-east-1\":\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={\"LocationConstraint\":current_region})\n",
    "        \n",
    "    print(bucket_name, current_region)\n",
    "    return bucket_name, bucket_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-train358f23b3-22ee-4d49-972b-293fb7d33344 us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name, first_response = create_bucket(\n",
    "    bucket_name='iris-train', \n",
    "    s3_connection=s3_resource.meta.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files into S3 Object<a id=\"File_Storage_Load\"></a>\n",
    "There is no native folder sync within Python SDK, so using aws command to solve for this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3.6 KiB/9.7 KiB (20.2 KiB/s) with 5 file(s) remaining\n",
      "upload: ../example_src/data/iris.csv to s3://iris-train358f23b3-22ee-4d49-972b-293fb7d33344/data/iris.csv\n",
      "Completed 3.6 KiB/9.7 KiB (20.2 KiB/s) with 4 file(s) remaining\n",
      "Completed 3.8 KiB/9.7 KiB (11.4 KiB/s) with 4 file(s) remaining\n",
      "upload: ../example_src/requirements.yml to s3://iris-train358f23b3-22ee-4d49-972b-293fb7d33344/requirements.yml\n",
      "Completed 3.8 KiB/9.7 KiB (11.4 KiB/s) with 3 file(s) remaining\n",
      "Completed 6.1 KiB/9.7 KiB (18.0 KiB/s) with 3 file(s) remaining\n",
      "upload: ../example_src/sm_train.py to s3://iris-train358f23b3-22ee-4d49-972b-293fb7d33344/sm_train.py\n",
      "Completed 6.1 KiB/9.7 KiB (18.0 KiB/s) with 2 file(s) remaining\n",
      "Completed 6.1 KiB/9.7 KiB (18.0 KiB/s) with 2 file(s) remaining\n",
      "upload: ../example_src/requirements.txt to s3://iris-train358f23b3-22ee-4d49-972b-293fb7d33344/requirements.txt\n",
      "Completed 6.1 KiB/9.7 KiB (18.0 KiB/s) with 1 file(s) remaining\n",
      "Completed 9.7 KiB/9.7 KiB (26.6 KiB/s) with 1 file(s) remaining\n",
      "upload: ../example_src/train.py to s3://iris-train358f23b3-22ee-4d49-972b-293fb7d33344/train.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "path_to_src = \"../example_src\"\n",
    "path_to_s3 = \"s3://\" + bucket_name\n",
    "\n",
    "# result = subprocess.run([\"aws\",\"s3\", \"sync\" ,path_to_src, path_to_s3,\"--acl\",\"private\"], stdout=subprocess.PIPE)\n",
    "\n",
    "result = os.popen(\"aws s3 sync \"+path_to_src+\" \"+path_to_s3+\" --acl private\").read()\n",
    "\n",
    "print(result)\n",
    "# [ print( l ) for l in result.stdout.decode('utf-8').split('\\n') ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to EC2](#Execute_Code_EC2)\n",
    "[Go to SageMaker](#Execute_Code_SM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete S3 Object and Content<a id=\"File_Storage_Delete\"></a>\n",
    "Remove all resources and delete bucket!<br>\n",
    "**This does not back-up anything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "def delete_all_objects(bucket_name):\n",
    "    res = []\n",
    "    bucket=s3_resource.Bucket(bucket_name)\n",
    "    for obj_version in bucket.object_versions.all():\n",
    "        res.append({'Key': obj_version.object_key,\n",
    "                    'VersionId': obj_version.id})\n",
    "    print(res)\n",
    "    if len(res) > 0:\n",
    "        bucket.delete_objects(Delete={'Objects': res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '47F879E285BFA452',\n",
       "  'HostId': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "   'x-amz-request-id': '47F879E285BFA452',\n",
       "   'date': 'Thu, 07 Nov 2019 00:51:55 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_all_objects(bucket_name)    \n",
    "\n",
    "s3_resource.Bucket(bucket_name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List S3 Buckets<a id=File_Storage_List></a>\n",
    "Quickly list and clean up all buckets created by with iris-trian in name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-traind73bd071-eb96-4720-bf80-a7dbf7887340\n",
      "[{'Key': 'data/iris.csv', 'VersionId': 'null'}, {'Key': 'requirements.txt', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'sm_train.py', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_resource = boto3.resource('s3')\n",
    "for bucket in s3_resource.buckets.all():\n",
    "  if \"iris-train\" in bucket.name:\n",
    "    print(bucket.name)\n",
    "    delete_all_objects(bucket.name)  \n",
    "    s3_resource.Bucket(bucket.name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Execute Code<a id=Execute_Code></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Instance<a id=Execute_Code_EC2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EC2 Instance<a id=Execute_Code_EC2_Create></a>\n",
    "https://blog.ipswitch.com/how-to-create-an-ec2-instance-with-python\n",
    "\n",
    "You need to bring your own:\n",
    "* Security Group\n",
    "* pem key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building the following EC2\n",
    "* MiniConda - ami-062c42cbecc1d5ec0\n",
    "* t2.medium\n",
    "\n",
    "I built my own security group and granted ssh access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_ec2_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a bash script to create the S3 Mount, go [here](#Execute_Code_EC2_Mount) to see details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount S3 onto EC2 Instance<a id=Execute_Code_EC2_Mount></a>\n",
    "https://cloudkul.com/blog/mounting-s3-bucket-linux-ec2-instance/\n",
    "\n",
    "Using existing EC2 in AWS\n",
    "Need to leverage API to create EC2 and mount determining setup\n",
    "\n",
    "**Required setup on EC2**\n",
    "```\n",
    "sudo yum update\n",
    "sudo yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel\n",
    "git clone https://github.com/s3fs-fuse/s3fs-fuse.git\n",
    "cd s3fs-fuse\n",
    "./autogen.sh\n",
    "./configure --prefix=/usr --with-openssl\n",
    "make\n",
    "sudo make install\n",
    "```\n",
    "\n",
    "You must create an IAM role for S3 Mounting, for sake of simplicity, i'm using my Admin IAM Access\n",
    "```\n",
    "sudo touch /etc/passwd-s3fs\n",
    "sudo vim /etc/passwd-s3fs\n",
    "```\n",
    "Provide `Your_accesskey:Your_secretkey` inside the file\n",
    "```\n",
    "sudo chmod 640 /etc/passwd-s3fs\n",
    "```\n",
    "\n",
    "Let's mount it!, replace iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 with your bucket name\n",
    "uid=500 is ec2-user account\n",
    "```\n",
    "sudo mkdir /mys3bucket\n",
    "sudo chown ec2-user:ec2-user /mys3bucket\n",
    "s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "\n",
    "Validate\n",
    "```\n",
    "df -Th\n",
    "```\n",
    "\n",
    "Mount at reboot\n",
    "```\n",
    "vi /etc/rc.local\n",
    "/usr/bin/s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "**or** add it to the User Data at execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "user_data = [\n",
    "    \"#cloud-boothook\",\n",
    "    \"#!/bin/bash\",\n",
    "    \"yum update -q -y\",\n",
    "    \"yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -q -y\",\n",
    "    \"git clone https://github.com/s3fs-fuse/s3fs-fuse.git /tmp/s3fs-fuse\",\n",
    "    \"cd /tmp/s3fs-fuse\",\n",
    "    \"./autogen.sh\",\n",
    "    \"./configure --prefix=/usr --with-openssl\",\n",
    "    \"make\",\n",
    "    \"make install\",\n",
    "    'echo \"' + os.getenv(\"AWS_ACCESS_ID\") + ':' + os.getenv(\"AWS_SECRET_ACCESS_KEY\") + '\" > /tmp/passwd-s3fs',\n",
    "    \"mv -f /tmp/passwd-s3fs /etc\",\n",
    "    \"chmod 640 /etc/passwd-s3fs\",\n",
    "    \"mkdir -p /mys3bucket\",\n",
    "    \"chown ec2-user:ec2-user /mys3bucket\",\n",
    "    \"s3fs \" + bucket_name + \" -o use_cache=/tmp -o uid=500 -o mp_umask=002 -o multireq_max=5 -o allow_other /mys3bucket\",\n",
    "    # \"while read requirement; do conda install --yes $requirement; done < /mys3bucket/requirements.txt\"\n",
    "]\n",
    "user_data = \"\\n\".join(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance id:  i-02076ade24fd81199\n",
      "Wait till instance state changes to running\n",
      "Instance State Up, waiting for boot-up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'instance is still loading retrying . . . '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance is UP & accessible on port 22, the IP address is:   52.91.206.192\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import boto3\n",
    "import socket\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "# create a new EC2 instance\n",
    "ec2_name = create_ec2_name(\"iris-train\")\n",
    "security_group = ['sg-0d24aec64507df8b5'] # SSH allowed\n",
    "pem_key =  os.getenv(\"AWS_PEM_KEY\")\n",
    "\n",
    "instances = ec2.create_instances(\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'instance',\n",
    "            'Tags': [\n",
    "                {\n",
    "                    'Key': 'Name',\n",
    "                    'Value': ec2_name\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    ImageId='ami-062c42cbecc1d5ec0',\n",
    "    MinCount=1,\n",
    "    MaxCount=1,\n",
    "    InstanceType='t2.micro',\n",
    "#     InstanceType='t2.medium',\n",
    "    KeyName=pem_key,\n",
    "    SecurityGroupIds=security_group, #Bring your own!\n",
    "    UserData=user_data\n",
    ")\n",
    "\n",
    "instance = instances[0]\n",
    "print(\"instance id: \",instance.id)\n",
    "\n",
    "#Provide status when instance is finally up!\n",
    "retries = 10\n",
    "retry_delay = 10\n",
    "retry_count = 0\n",
    "\n",
    "print(\"Wait till instance state changes to running\")\n",
    "instance.wait_until_running()\n",
    "instance = ec2.Instance(id=instance.id)\n",
    "print(\"Instance State Up, waiting for boot-up\")\n",
    "\n",
    "waiting_status = \"instance is still loading retrying . . . \"\n",
    "dh = display(waiting_status,display_id=True)\n",
    "\n",
    "while retry_count <= retries:\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex((instance.public_ip_address,22))\n",
    "    if result == 0:\n",
    "        print(\"Instance is UP & accessible on port 22, the IP address is:  \",instance.public_ip_address)\n",
    "        break\n",
    "    else:\n",
    "        if len(waiting_status) < 50:\n",
    "            waiting_status += \". \"\n",
    "        else:\n",
    "            waiting_status = waiting_status[0:41]\n",
    "\n",
    "        dh.update(waiting_status)\n",
    "        time.sleep(retry_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands via SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "# import boto\n",
    "import paramiko\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "pem_key = os.getenv(\"AWS_PEM_KEY\")\n",
    "pem_location = os.getenv(\"AWS_PEM_LOCATION\")\n",
    "pub_dns_name = instance.public_ip_address\n",
    "\n",
    "def exec_cmd_ec2(public_dns_name,cmd):\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    privkey = paramiko.RSAKey.from_private_key_file(pem_location+pem_key+'.pem')\n",
    "    ssh.connect(public_dns_name,username='ec2-user',pkey=privkey)\n",
    "    stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "    stdin.flush()\n",
    "    data = stdout.read().splitlines()\n",
    "    ssh.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I can tell miniconda app happens after UserData is complete, thus no installing conda environment\n",
    "\n",
    "We will execute the following command through ssh client via root access\n",
    "```\n",
    "sudo su\n",
    "while read requirement; do conda install --yes $requirement; done < /mys3bucket/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"mkdir /mys3bucket/output\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"mkdir /mys3bucket/model\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"echo 'for requirement in `cat /mys3bucket/requirements.txt` ; do  conda install --yes  ${requirement}  ;  done' > /mys3bucket/setup.sh\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"chmod +x /mys3bucket/setup.sh\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"sudo  -i /mys3bucket/setup.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Python Script<a id=Execute_Code_EC2_Script></a>\n",
    "\n",
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the train.py file!\n",
    "```\n",
    "cd /mys3bucket\n",
    "python train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Starting the training.'\n",
      "b'Fitting 5 folds for each of 36 candidates, totalling 180 fits'\n",
      "b'Training complete.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"cd /mys3bucket/; python /mys3bucket/train.py\")\n",
    "\n",
    "[ print(l) for l in ssh_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop \\ Terminate EC2 Instance<a id=Execute_Code_EC2_Stop></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('ec2')\n",
    "\n",
    "response = client.stop_instances(\n",
    "    InstanceIds=[\n",
    "        instances[0].id,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'StoppingInstances': [{'CurrentState': {'Code': 64, 'Name': 'stopping'},\n",
       "   'InstanceId': 'i-02076ade24fd81199',\n",
       "   'PreviousState': {'Code': 16, 'Name': 'running'}}],\n",
       " 'ResponseMetadata': {'RequestId': 'e75439cf-78b4-4287-863f-c5cd7515f6ac',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '579',\n",
       "   'date': 'Tue, 12 Nov 2019 02:43:59 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Sagemaker<a id=Execute_Code_SM></a>\n",
    "Sagemaker requires setting up the S3 Folder Structure alittle differently\n",
    "```\n",
    "example_src/\n",
    "+----data/\n",
    "    +--iris.csv\n",
    "+----output/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup S3<a id=Execute_Code_SM_S3></a>\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris/Scikit-learn%20Estimator%20Example%20With%20Batch%20Transform.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# from sagemaker import get_execution_role\n",
    "# role = get_execution_role()\n",
    "# role\n",
    "role = \"arn:aws:iam::741519135447:role/service-role/AmazonSageMaker-ExecutionRole-20191018T183794\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-741519135447/iris-train/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset, then join labels and features\n",
    "iris = datasets.load_iris()\n",
    "joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# Create directory and write csv\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "np.savetxt('./data/iris.csv', joined_iris, delimiter=',', fmt='%1.1f, %1.3f, %1.3f, %1.3f, %1.3f')\n",
    "\n",
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(\"iris-train\", WORK_DIRECTORY) )\n",
    "\n",
    "print(train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = '../example_src/sm_train.py'\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'max_leaf_nodes': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-10 22:56:06 Starting - Starting the training job...\n",
      "2019-11-10 22:56:11 Starting - Launching requested ML instances.........\n",
      "2019-11-10 22:57:42 Starting - Preparing the instances for training...\n",
      "2019-11-10 22:58:36 Downloading - Downloading input data...\n",
      "2019-11-10 22:58:58 Training - Downloading the training image..\u001b[31m2019-11-10 22:59:18,182 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,185 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,195 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,495 sagemaker-containers INFO     Module sm_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,495 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,495 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:18,495 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: sm-train\n",
      "  Building wheel for sm-train (setup.py): started\n",
      "  Building wheel for sm-train (setup.py): finished with status 'done'\n",
      "  Created wheel for sm-train: filename=sm_train-1.0.0-py2.py3-none-any.whl size=6200 sha256=08bfa160905b9ddc392e9c59b50aabcb3231be4d7c8df7bb47369d2deabe01b6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0gi9qm42/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built sm-train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: sm-train\u001b[0m\n",
      "\u001b[31mSuccessfully installed sm-train-1.0.0\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:19,849 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:19,860 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_leaf_nodes\": 30\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-11-10-22-56-06-322\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-10-22-56-06-322/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sm_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sm_train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"max_leaf_nodes\":30}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=sm_train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=sm_train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-10-22-56-06-322/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_leaf_nodes\":30},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2019-11-10-22-56-06-322\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-741519135447/sagemaker-scikit-learn-2019-11-10-22-56-06-322/source/sourcedir.tar.gz\",\"module_name\":\"sm_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sm_train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--max_leaf_nodes\",\"30\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_MAX_LEAF_NODES=30\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/miniconda3/bin/python -m sm_train --max_leaf_nodes 30\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[31m/opt/ml/code/sm_train.py:33: FutureWarning: \u001b[0m\n",
      "\u001b[31m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[31m.loc for label based indexing or\u001b[0m\n",
      "\u001b[31m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[31mSee the documentation here:\u001b[0m\n",
      "\u001b[31mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_y = train_data.ix[:,0]\u001b[0m\n",
      "\u001b[31m/opt/ml/code/sm_train.py:34: FutureWarning: \u001b[0m\n",
      "\u001b[31m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[31m.loc for label based indexing or\u001b[0m\n",
      "\u001b[31m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[31mSee the documentation here:\u001b[0m\n",
      "\u001b[31mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  train_X = train_data.ix[:,1:]\u001b[0m\n",
      "\u001b[31m/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py:822: FutureWarning: \u001b[0m\n",
      "\u001b[31m.ix is deprecated. Please use\u001b[0m\n",
      "\u001b[31m.loc for label based indexing or\u001b[0m\n",
      "\u001b[31m.iloc for positional indexing\n",
      "\u001b[0m\n",
      "\u001b[31mSee the documentation here:\u001b[0m\n",
      "\u001b[31mhttp://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\u001b[0m\n",
      "\u001b[31m2019-11-10 22:59:21,139 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-11-10 22:59:28 Uploading - Uploading generated training model\n",
      "2019-11-10 22:59:28 Completed - Training job completed\n",
      "Training seconds: 52\n",
      "Billable seconds: 52\n"
     ]
    }
   ],
   "source": [
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sagemaker-scikit-learn-2019-11-10-22-56-06-322: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-fbafc7f42df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ml.m4.xlarge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             )\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m    980\u001b[0m         )\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py/miniconda3/envs/pycloud/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   1177\u001b[0m                 ),\n\u001b[1;32m   1178\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m             )\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sagemaker-scikit-learn-2019-11-10-22-56-06-322: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"data/iris.csv\", header=None)\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "test_X = test_data.iloc[:,1:]\n",
    "test_y = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-74840b08a93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(predictor.predict(test_X.values))\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "Following Workflow\n",
    "\n",
    "### [File Storage](#File_Storage)\n",
    "* [Create](#File_Storage_Create) an **S3 Bucket**\n",
    "* [Load](#File_Storage_Load) csv file and script to execute\n",
    "* [Delete](#File_Storage_Delete) object and content\n",
    "\n",
    "### [Execute Code](#Execute_Code)\n",
    "#### [EC2](#Execute_Code_EC2) Miniconda Image\n",
    "* [Create](#Execute_Code_EC2_Create) the EC2 Instance\n",
    "* [Mount](#Execute_Code_EC2_Mount) S3 Storage\n",
    "* Determine mechanism to execute script\n",
    "* Shut down server\n",
    "\n",
    "#### SageView Instance\n",
    "* Create SageView\n",
    "* Mount S3 Storage\n",
    "* Execute Script\n",
    "\n",
    "### Requirements\n",
    "pycloud environment\n",
    "```\n",
    "conda env create -f pycloud.env.ymp --force\n",
    "```\n",
    "\n",
    "From Command line execute `aws configure` in order to setup your AWS Access Key and AWS Secret Key\n",
    "\n",
    "Local Test Code is located under `example_src`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## File Storage<a id=\"File_Storage\"></a>\n",
    "Code to create an S3 Storage\n",
    "https://realpython.com/python-boto3-aws-s3/#creating-a-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Object<a id=\"File_Storage_Create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_bucket_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])\n",
    "\n",
    "def create_bucket(bucket_prefix, s3_connection):\n",
    "    session = boto3.session.Session()\n",
    "    current_region = session.region_name\n",
    "    # Create Configurations\n",
    "    configs = {}\n",
    "    if current_region != \"us-east-1\":\n",
    "        config[\"LocationConstraint\"] = current_region\n",
    "\n",
    "    bucket_name = create_bucket_name(bucket_prefix)\n",
    "    \n",
    "    if current_region == \"us-east-1\":\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name)\n",
    "    else:\n",
    "        bucket_response = s3_connection.create_bucket(\n",
    "            Bucket=bucket_name,\n",
    "            CreateBucketConfiguration={\"LocationConstraint\":current_region})\n",
    "        \n",
    "    print(bucket_name, current_region)\n",
    "    return bucket_name, bucket_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a us-east-1\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name, first_response = create_bucket(\n",
    "    bucket_prefix='iris-train', \n",
    "    s3_connection=s3_resource.meta.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files into S3 Object<a id=\"File_Storage_Load\"></a>\n",
    "There is no native folder sync within Python SDK, so using aws command to solve for this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3.6 KiB/73.7 KiB (20.7 KiB/s) with 4 file(s) remaining\n",
      "upload: ../example_src/data/training/iris.csv to s3://iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a/data/training/iris.csv\n",
      "Completed 3.6 KiB/73.7 KiB (20.7 KiB/s) with 3 file(s) remaining\n",
      "Completed 3.8 KiB/73.7 KiB (12.0 KiB/s) with 3 file(s) remaining\n",
      "upload: ../example_src/requirements.yml to s3://iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a/requirements.yml\n",
      "Completed 3.8 KiB/73.7 KiB (12.0 KiB/s) with 2 file(s) remaining\n",
      "Completed 7.4 KiB/73.7 KiB (21.8 KiB/s) with 2 file(s) remaining\n",
      "upload: ../example_src/train.py to s3://iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a/train.py\n",
      "Completed 7.4 KiB/73.7 KiB (21.8 KiB/s) with 1 file(s) remaining\n",
      "Completed 73.7 KiB/73.7 KiB (77.5 KiB/s) with 1 file(s) remaining\n",
      "upload: ../example_src/model/iris-randomforest.pkl to s3://iris-trainfc0346c3-df2f-4aa3-8e80-6961e6a1a17a/model/iris-randomforest.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "path_to_src = \"../example_src\"\n",
    "path_to_s3 = \"s3://\" + bucket_name\n",
    "\n",
    "# result = subprocess.run([\"aws\",\"s3\", \"sync\" ,path_to_src, path_to_s3,\"--acl\",\"private\"], stdout=subprocess.PIPE)\n",
    "\n",
    "result = os.popen(\"aws s3 sync \"+path_to_src+\" \"+path_to_s3+\" --acl private\").read()\n",
    "\n",
    "print(result)\n",
    "# [ print( l ) for l in result.stdout.decode('utf-8').split('\\n') ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete S3 Object and Content<a id=\"File_Storage_Delete\"></a>\n",
    "Remove all resources and delete bucket!<br>\n",
    "**This does not back-up anything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'data/training/iris.csv', 'VersionId': 'null'}, {'Key': 'model/iris-randomforest.pkl', 'VersionId': 'null'}, {'Key': 'requirements.yml', 'VersionId': 'null'}, {'Key': 'train.py', 'VersionId': 'null'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '47F879E285BFA452',\n",
       "  'HostId': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'g1Ue8rg/KEvdhrCMP6mJLjm0C8wsDkzikdkswbQ7ajcpnaVSepVP6xEK+g4GT/a+G6RkTg41m3Q=',\n",
       "   'x-amz-request-id': '47F879E285BFA452',\n",
       "   'date': 'Thu, 07 Nov 2019 00:51:55 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete_all_objects(bucket_name):\n",
    "    res = []\n",
    "    bucket=s3_resource.Bucket(bucket_name)\n",
    "    for obj_version in bucket.object_versions.all():\n",
    "        res.append({'Key': obj_version.object_key,\n",
    "                    'VersionId': obj_version.id})\n",
    "    print(res)\n",
    "    bucket.delete_objects(Delete={'Objects': res})\n",
    "\n",
    "delete_all_objects(bucket_name)    \n",
    "\n",
    "s3_resource.Bucket(bucket_name).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top](#top)\n",
    "## Execute Code<a id=Execute_Code></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 Instance<a id=Execute_Code_EC2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EC2 Instance<a id=Execute_Code_EC2_Create></a>\n",
    "https://blog.ipswitch.com/how-to-create-an-ec2-instance-with-python\n",
    "\n",
    "You need to bring your own:\n",
    "* Security Group\n",
    "* pem key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building the following EC2\n",
    "* MiniConda - ami-062c42cbecc1d5ec0\n",
    "* t2.medium\n",
    "\n",
    "I built my own security group and granted ssh access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_ec2_name(bucket_prefix):\n",
    "    # The generated bucket name must be between 3 and 63 chars long\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a bash script to create the S3 Mount, go [here](#Execute_Code_EC2_Mount) to see details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "user_data = [\n",
    "    \"#cloud-boothook\",\n",
    "    \"#!/bin/bash\",\n",
    "    \"yum update -q -y\",\n",
    "    \"yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel -q -y\",\n",
    "    \"git clone https://github.com/s3fs-fuse/s3fs-fuse.git /tmp/s3fs-fuse\",\n",
    "    \"cd /tmp/s3fs-fuse\",\n",
    "    \"./autogen.sh\",\n",
    "    \"./configure --prefix=/usr --with-openssl\",\n",
    "    \"make\",\n",
    "    \"make install\",\n",
    "    'echo \"' + os.getenv(\"AWS_ACCESS_ID\") + ':' + os.getenv(\"AWS_SECRET_ACCESS_KEY\") + '\" > /tmp/passwd-s3fs',\n",
    "    \"mv -f /tmp/passwd-s3fs /etc\",\n",
    "    \"chmod 640 /etc/passwd-s3fs\",\n",
    "    \"mkdir -p /mys3bucket\",\n",
    "    \"chown ec2-user:ec2-user /mys3bucket\",\n",
    "    \"s3fs \" + bucket_name + \" -o use_cache=/tmp -o uid=500 -o mp_umask=002 -o multireq_max=5 -o allow_other /mys3bucket\",\n",
    "    \"while read requirement; do conda install --yes $requirement; done < requirements.txt\"\n",
    "]\n",
    "user_data = \"\\n\".join(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ec2.Instance(id='i-0b0661e348f96614f')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "ec2 = boto3.resource('ec2')\n",
    "\n",
    "# create a new EC2 instance\n",
    "ec2_name = create_ec2_name(\"iris-train\")\n",
    "security_group = ['sg-0d24aec64507df8b5'] # SSH allowed\n",
    "pem_key = \"ballenger-smu\"\n",
    "\n",
    "instances = ec2.create_instances(\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            'ResourceType': 'instance',\n",
    "            'Tags': [\n",
    "                {\n",
    "                    'Key': 'Name',\n",
    "                    'Value': ec2_name\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    ImageId='ami-062c42cbecc1d5ec0',\n",
    "    MinCount=1,\n",
    "    MaxCount=1,\n",
    "    InstanceType='t2.medium',\n",
    "    KeyName=pem_key,\n",
    "    SecurityGroupIds=security_group, #Bring your own!\n",
    "    UserData=user_data\n",
    ")\n",
    "\n",
    "instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands via SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo mkdir -p /mys3bucket\n",
      "sudo chown ec2-user:ec2-user /mys3bucket\n",
      "s3fs iris-traina35ddbe4-aab9-4186-aefc-7654bde70442 -o use_cache=/tmp -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
      "cd /mys3bucket\n",
      "conda env create -f /mys3bucket/pycloud.env.yml\n"
     ]
    }
   ],
   "source": [
    "print(\"sudo mkdir -p /mys3bucket\")\n",
    "print(\"sudo chown ec2-user:ec2-user /mys3bucket\")\n",
    "print(\"s3fs \"+bucket_name+\" -o use_cache=/tmp -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\")\n",
    "print(\"cd /mys3bucket\")\n",
    "print(\"conda env create -f /mys3bucket/pycloud.env.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import boto\n",
    "import paramiko\n",
    "\n",
    "pem_key = \"ec2-keypair\"\n",
    "pem_location =\"/Users/venkatkasarla/Downloads/AWS-Cloud/\"\n",
    "pub_dns_name=\"ec2-3-81-47-174.compute-1.amazonaws.com\"\n",
    "\n",
    "def exec_cmd_ec2(public_dns_name,cmd):\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    privkey = paramiko.RSAKey.from_private_key_file(pem_location+pem_key+'.pem')\n",
    "    ssh.connect(public_dns_name,username='ec2-user',pkey=privkey)\n",
    "    stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "    stdin.flush()\n",
    "    data = stdout.read().splitlines()\n",
    "    ssh.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"mkdir /mys3bucket/output\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"mkdir /mys3bucket/model\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"echo 'for requirement in `cat /mys3bucket/requirements.txt` ; do  conda install --yes  ${requirement}  ;  done' > /mys3bucket/setup.sh\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"chmod +x /mys3bucket/setup.sh\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"sudo  -i /mys3bucket/setup.sh\")\n",
    "ssh_result = exec_cmd_ec2(pub_dns_name,\"cd /mys3bucket/; python /mys3bucket/train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount S3 onto EC2 Instance<a id=Execute_Code_EC2_Mount></a>\n",
    "https://cloudkul.com/blog/mounting-s3-bucket-linux-ec2-instance/\n",
    "\n",
    "Using existing EC2 in AWS\n",
    "Need to leverage API to create EC2 and mount determining setup\n",
    "\n",
    "**Required setup on EC2**\n",
    "```\n",
    "sudo yum update\n",
    "sudo yum install automake fuse fuse-devel gcc-c++ git libcurl-devel libxml2-devel make openssl-devel\n",
    "git clone https://github.com/s3fs-fuse/s3fs-fuse.git\n",
    "cd s3fs-fuse\n",
    "./autogen.sh\n",
    "./configure --prefix=/usr --with-openssl\n",
    "make\n",
    "sudo make install\n",
    "```\n",
    "\n",
    "You must create an IAM role for S3 Mounting, for sake of simplicity, i'm using my Admin IAM Access\n",
    "```\n",
    "sudo touch /etc/passwd-s3fs\n",
    "sudo vim /etc/passwd-s3fs\n",
    "```\n",
    "Provide `Your_accesskey:Your_secretkey` inside the file\n",
    "```\n",
    "sudo chmod 640 /etc/passwd-s3fs\n",
    "```\n",
    "\n",
    "Let's mount it!, replace iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 with your bucket name\n",
    "uid=500 is ec2-user account\n",
    "```\n",
    "sudo mkdir /mys3bucket\n",
    "sudo chown ec2-user:ec2-user /mys3bucket\n",
    "s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "\n",
    "Validate\n",
    "```\n",
    "df -Th\n",
    "```\n",
    "\n",
    "Mount at reboot\n",
    "```\n",
    "vi /etc/rc.local\n",
    "/usr/bin/s3fs iris-trainc0e3588c-d9bb-4699-821c-1883670ace42 -o use_cache=/tmp -o allow_other -o uid=500 -o mp_umask=002 -o multireq_max=5 /mys3bucket\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Conda to work\n",
    "\n",
    "```\n",
    "sudo chown -R ec2-user:ec2-user /opt/conda\n",
    "conda update -n base -c defaults conda\n",
    "conda env update -n base --file requirements.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
